{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing the dataset to suit the Trie Structure\n",
    "- The dataset is formatted into the format of \n",
    "- WSD word, PosTag, Sentence, SenseTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying the WSD word from the data \n",
    "def wsdword(text):\n",
    "    match = re.search(r'<WSD>(.*?)<WSD>', text)\n",
    "    if match:\n",
    "        word_inside_wsd = match.group(1)\n",
    "        return word_inside_wsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag(sentence):\n",
    "    input=sentence.split(\".\")\n",
    "    return input[1]\n",
    "\n",
    "def wsdwordsensetag(sentence):\n",
    "    input=sentence.split(\".\")\n",
    "    return input[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the sentence without <wsd> token and the index\n",
    "def extract_sentence(sentence):\n",
    "    # Find the start and end index of the <WSD> tags\n",
    "    start_index = sentence.find('<WSD>')    \n",
    "    end_index = sentence.find('</WSD>')\n",
    "    \n",
    "\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        # Extract the word between <WSD> tags\n",
    "        word = sentence[start_index + len('<WSD>'):end_index]\n",
    "\n",
    "        # Remove <WSD> and </WSD> tags from the sentence\n",
    "        cleaned_sentence = sentence[:start_index] + word+\" \" + sentence[end_index + len('</WSD>'):]\n",
    "        #finding the index of the word\n",
    "\n",
    "        list_word=cleaned_sentence.split(\" \")\n",
    "        \n",
    "\n",
    "        return cleaned_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file2 = open(\"train/process_dataset.txt\",\"w\",encoding=\"utf-8\")\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = 'train/semcor_it.csv'\n",
    "\n",
    "# Open the CSV file\n",
    "with open(csv_file_path, mode='r', newline='',encoding=\"utf-8\") as file:\n",
    "    # Create a CSV reader object\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    \n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in csv_reader:\n",
    "        # Access the columns by their header names\n",
    "        sentence = row['sentence']\n",
    "        fileid = row['fileid']\n",
    "        senseid = row['senseid'].strip()\n",
    "               \n",
    "        # Print or process each row\n",
    "        try:\n",
    "            file2.write(wsdword(sentence)+\"\\t\"+senseid[-1]+\"\\t\"+sentence+\"\\t\"+senseid+\"\\n\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # You can perform other operations with the row data here\n",
    "  \n",
    "\n",
    "file2.close()\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file2 = open(\"train/process_dataset2.txt\",\"w\", encoding=\"utf-8\")\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = 'train/wngt_it.csv'\n",
    "\n",
    "# Open the CSV file\n",
    "with open(csv_file_path, mode='r', newline='',encoding=\"utf-8\") as file:\n",
    "    # Create a CSV reader object\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    \n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in csv_reader:\n",
    "        # Access the columns by their header names\n",
    "        sentence = row['sentence']\n",
    "        fileid = row['fileid']\n",
    "        senseid = row['senseid'].strip()\n",
    "               \n",
    "        # Print or process each row\n",
    "        try:\n",
    "            file2.write(wsdword(sentence)+\"\\t\"+senseid[-1]+\"\\t\"+sentence+\"\\t\"+senseid+\"\\n\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # You can perform other operations with the row data here\n",
    "  \n",
    "\n",
    "file2.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Buiding the dictionary based on the key and the noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nested_dictionary():\n",
    "    data_dict = {}\n",
    "    file1= open(\"train/process_dataset.txt\",\"r\")\n",
    "\n",
    "    for line in file1:\n",
    "        # Split the line into words\n",
    "        words = line.split(\"\\t\")\n",
    "\n",
    "        if len(words) >= 2:\n",
    "            # Extract the first word as the key\n",
    "            key = words[0].lower()\n",
    "\n",
    "            # Extract the second word as the nested key\n",
    "            nested_key = words[1]\n",
    "\n",
    "            # Extract the remaining words as the value\n",
    "            value = ','.join(words[2:])\n",
    "\n",
    "            # Check if the key already exists in the dictionary\n",
    "            if key in data_dict:\n",
    "                # Check if the nested key exists in the nested dictionary\n",
    "                if nested_key in data_dict[key]:\n",
    "                    # Append the value to the existing list of values for the nested key\n",
    "                    data_dict[key][nested_key].append(value)\n",
    "                else:\n",
    "                    # Create a new list for the nested key and store the value\n",
    "                    data_dict[key][nested_key] = [value]\n",
    "            else:\n",
    "                # Create a new nested dictionary for the key and store the value\n",
    "                data_dict[key] = {nested_key: [value]}\n",
    "    file1.close()\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary=build_nested_dictionary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, nested_dict in data_dictionary.items():\n",
    "    print(f\"{key}: {nested_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary_to_file(data_dict, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dictionary_to_file(data_dictionary, 'my_dictionary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_dictionary_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            data_dict = json.load(file)\n",
    "        return data_dict\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the file doesn't exist\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        # Handle the case where the file contains invalid JSON\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict = load_dictionary_from_file(\"my_dictionary.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=loaded_dict[\"obiettivi\"][\"n\"]\n",
    "print(examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
